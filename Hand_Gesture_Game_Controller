import cv2
import mediapipe as mp
import pyautogui
import pygetwindow as gw
import time

# â›³ Step 1: Set your exact game window title
GAME_WINDOW_TITLE = "Hill Climb Racing"  # Use print(gw.getAllTitles()) to confirm

# ğŸ¯ Step 2: Focus the game window
def focus_game_window():
    try:
        windows = gw.getWindowsWithTitle(GAME_WINDOW_TITLE)
        if windows:
            windows[0].activate()
            print(f"âœ… Focused window: {GAME_WINDOW_TITLE}")
        else:
            print("âŒ Game window not found.")
    except Exception as e:
        print(f"âŒ Error focusing window: {e}")

# âœ‹ Step 3: Setup MediaPipe for hand tracking
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1)
mp_draw = mp.solutions.drawing_utils

# ğŸ¥ Step 4: Start webcam
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("âŒ Could not access webcam.")
    exit()

# ğŸ‘ï¸â€ğŸ—¨ï¸ Step 5: Define gesture logic
def is_hand_open(hand_landmarks):
    tips = [4, 8, 12, 16, 20]
    fingers = []
    fingers.append(hand_landmarks.landmark[tips[0]].x < hand_landmarks.landmark[tips[0]-1].x)
    for i in range(1, 5):
        fingers.append(hand_landmarks.landmark[tips[i]].y < hand_landmarks.landmark[tips[i]-2].y)
    return sum(fingers) >= 4

# ğŸš¦ Step 6: Start control loop
last_action = None

print("ğŸš€ Starting Hand Gesture Controller...")
time.sleep(2)
focus_game_window()
print("ğŸ® Ready! ğŸ–ï¸ = Accelerate â†’ | âœŠ = Brake â† | Press ESC to exit")

while True:
    success, frame = cap.read()
    if not success:
        break

    frame = cv2.flip(frame, 1)
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(rgb)

    gesture = "No Hand"

    if result.multi_hand_landmarks:
        for handLms in result.multi_hand_landmarks:
            mp_draw.draw_landmarks(frame, handLms, mp_hands.HAND_CONNECTIONS)

            if is_hand_open(handLms):
                gesture = "Accelerate â†’"
                if last_action != "right":
                    pyautogui.keyDown("right")
                    pyautogui.keyUp("left")
                    last_action = "right"
            else:
                gesture = "Brake â†"
                if last_action != "left":
                    pyautogui.keyDown("left")
                    pyautogui.keyUp("right")
                    last_action = "left"
    else:
        pyautogui.keyUp("right")
        pyautogui.keyUp("left")
        last_action = None

    # ğŸ–¼ï¸ Show live webcam feed
    cv2.putText(frame, f"Gesture: {gesture}", (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.imshow("ğŸ–ï¸ Hill Climb Gesture Control", cv2.resize(frame, (320, 240)))
    cv2.moveWindow("ğŸ–ï¸ Hill Climb Gesture Control", 1000, 10)

    if cv2.waitKey(1) & 0xFF == 27:
        break

# ğŸ§¹ Step 7: Cleanup
cap.release()
cv2.destroyAllWindows()
pyautogui.keyUp("right")
pyautogui.keyUp("left")
